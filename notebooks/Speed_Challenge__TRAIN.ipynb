{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ELU\n",
    "from keras.layers import Lambda, Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/history.p \n",
      " ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5 \n",
      " ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400\n"
     ]
    }
   ],
   "source": [
    "model_name = 'keras'\n",
    "batch_size = 20\n",
    "epoch_num = 20\n",
    "steps_per_epoch = 400\n",
    "\n",
    "asset_path = '../train/assets'\n",
    "train_name = f'model={model_name}-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}'\n",
    "train_path = os.path.join(asset_path, train_name)\n",
    "\n",
    "history_loc = os.path.join(train_path, 'history.p')\n",
    "weights_loc = os.path.join(train_path, 'weights.h5')\n",
    "tensorboard_loc = os.path.join(train_path, train_name)\n",
    "print(history_loc, '\\n', weights_loc, '\\n', tensorboard_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 320, 3) 136 320 3\n"
     ]
    }
   ],
   "source": [
    "# Global Vars\n",
    "img = (cv.imread('../train/photos/images/gray_Clipped/0.jpg')).shape\n",
    "img_height = img[0]\n",
    "img_width = img[1]\n",
    "img_channels = img[2]\n",
    "print(img, img_height, img_width, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_Value(prvs_FRAME, curr_FRAME, HSV_value):\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME, cv.COLOR_BGR2HSV)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME, cv.COLOR_BGR2HSV)\n",
    "    prvs_FRAME[...,2] = prvs_FRAME[...,2]*HSV_value\n",
    "    curr_FRAME[...,2] = curr_FRAME[...,2]*HSV_value\n",
    "    return prvs_FRAME, curr_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlow_DENSE(prvs_FRAME, curr_FRAME):\n",
    "    # flow_mat = None\n",
    "    # image_scale = 0.5\n",
    "    # pyr_images = 1 # was 3\n",
    "    # win_size = 15\n",
    "    # pyr_iterations = 2 # was 3\n",
    "    # poly_expans = 5\n",
    "    # std = 1.3 # was 1.2\n",
    "    \n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    pyr_images = 1 # was 3\n",
    "    win_size = 10\n",
    "    pyr_iterations = 2 # was 3\n",
    "    poly_expans = 5\n",
    "    std = 1.3 # was 1.2\n",
    "\n",
    "    hsv = np.zeros_like(prvs_FRAME)\n",
    "    hsv[...,1] = 255\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME,cv.COLOR_BGR2GRAY)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME,cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs_FRAME,curr_FRAME,flow_mat,image_scale,pyr_images,win_size,pyr_iterations,poly_expans,std,0)\n",
    "    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(train_meta, kLoopCount, train_index):\n",
    "    opt_flows = np.empty((0, img_height, img_width, img_channels), dtype='uint8')\n",
    "    speed = np.empty((0))\n",
    "    for k in range(kLoopCount):\n",
    "        HSV_value = np.random.uniform(low=.7, high=1.4)\n",
    "        curr_FRAME = cv.imread(train_meta['image_path'][train_index])\n",
    "        #curr_FRAME = curr_FRAME[100:440, :-90]\n",
    "        prvs_FRAME = cv.imread(train_meta['image_path'][train_index-1])\n",
    "        #prvs_FRAME = prvs_FRAME[100:440, :-90]\n",
    "        speed = np.append(speed, train_meta['speed'][train_index])\n",
    "        prvs_FRAME, curr_FRAME = adjust_Value(prvs_FRAME, curr_FRAME, HSV_value)\n",
    "        opt_flow = opticalFlow_DENSE(prvs_FRAME, curr_FRAME)\n",
    "        opt_flow.dtype = 'uint8'\n",
    "        opt_flows = np.append(opt_flows, [opt_flow], axis=0)\n",
    "    return opt_flows, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData(train_meta, train_index, kLoopCount):\n",
    "    global img_height, img_width, img_channels\n",
    "    while True:\n",
    "        opt_flow_arr = np.empty((0, img_height, img_width, img_channels))\n",
    "        speed_arr = np.empty((0))\n",
    "        for i in range(kLoopCount):\n",
    "            index = np.random.randint(0, train_index.shape[0])\n",
    "            opt_flow, speed = getData(train_meta, kLoopCount, train_index[index])\n",
    "            opt_flow_arr = np.append(opt_flow_arr, opt_flow, axis=0)\n",
    "            speed_arr = np.append(speed_arr, speed)\n",
    "        yield opt_flow_arr, speed_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValData(train_meta, val_index, kLoopCount):\n",
    "    while True:\n",
    "        for i in range(len(val_index)):\n",
    "            index = 0\n",
    "            opt_flow, speed = getData(train_meta, kLoopCount, val_index[index])\n",
    "            #opt_flow_arr = np.append(opt_flow_arr, opt_flow)\n",
    "            yield opt_flow, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCNNModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=40, kernel_size=(5,5), strides=(3,3), activation='relu', input_shape=(136,320,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(2,2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dense(units=15, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='relu'))\n",
    "    #adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    global batch_size, epoch_num, steps_per_epoch, train_path\n",
    "    train_csv_path = '../train/text/CSV'\n",
    "    train_meta = pd.read_csv(os.path.join(train_csv_path, 'trainGrayClipped_meta.csv'))\n",
    "    \n",
    "    data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "    dataset_frames_num = train_meta.shape[0]\n",
    "    train_frames_num = int(.8*(dataset_frames_num-1))\n",
    "    \n",
    "    train_index = data_index[:train_frames_num]\n",
    "    val_index = data_index[train_frames_num:]\n",
    "    print(train_index.shape, val_index.shape)\n",
    "    \n",
    "    #getTrainingData(train_meta, train_index, epoch_num)\n",
    "    #getValData(train_meta, val_index, epoch_num)\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "    \n",
    "    valid_generator = getValData(train_meta, val_index, batch_size)\n",
    "    val_size = len(val_index)\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                                  patience=1, \n",
    "                                  verbose=1, \n",
    "                                  min_delta = 0.23,\n",
    "                                  mode='min',)\n",
    "    \n",
    "    modelCheckpoint = ModelCheckpoint(weights_loc, \n",
    "                                      monitor = 'val_loss', \n",
    "                                      save_best_only = True, \n",
    "                                      mode = 'min', \n",
    "                                      verbose = 1,\n",
    "                                     save_weights_only = True)\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0,\n",
    "                                write_graph=True, write_images=True)\n",
    "    callbacks_list = [modelCheckpoint, tensorboard, earlyStopping]\n",
    "    \n",
    "    model = createCNNModel()\n",
    "    \n",
    "    train_size = len(train_index)\n",
    "    train_generator = getTrainingData(train_meta, train_index, batch_size)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            steps_per_epoch = steps_per_epoch, \n",
    "            epochs = epoch_num,\n",
    "            callbacks = callbacks_list,\n",
    "            verbose = 1,\n",
    "            validation_data = valid_generator,\n",
    "            validation_steps = val_size)\n",
    "\n",
    "    print(history)\n",
    "    pickle.dump(history.history, open(history_loc, \"wb\"))\n",
    "    \n",
    "    return model, history.history, valid_generator, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16319,) (4080,)\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 2664s 7s/step - loss: 28.0178 - val_loss: 7.7919\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.79187, saving model to ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 2564s 6s/step - loss: 15.5243 - val_loss: 5.2892\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.79187 to 5.28923, saving model to ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 2556s 6s/step - loss: 11.3068 - val_loss: 2.2013\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.28923 to 2.20130, saving model to ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 2549s 6s/step - loss: 12.2778 - val_loss: 1.8348\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.20130 to 1.83484, saving model to ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 2553s 6s/step - loss: 11.8939 - val_loss: 0.8616\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.83484 to 0.86163, saving model to ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 2583s 6s/step - loss: 10.6559 - val_loss: 0.3524\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.86163 to 0.35242, saving model to ../train/assets/model=keras-batch_size=20-num_epoch=20-steps_per_epoch=400/weights.h5\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 2576s 6s/step - loss: 10.7069 - val_loss: 0.5508\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35242\n",
      "Epoch 00007: early stopping\n",
      "<keras.callbacks.callbacks.History object at 0x7efc5e662340>\n"
     ]
    }
   ],
   "source": [
    "model, history, valid_generator, val_size = start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle.load(open(history_loc, \"rb\" ))\n",
    "model.load_weights(weights_loc)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = adam, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = model.evaluate_generator(valid_generator, steps=val_size)\n",
    "print('val score:', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc545f7190>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], 'ro')\n",
    "plt.plot(history['val_loss'], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size)\n",
    "fig_size[0] = 30\n",
    "fig_size[1] = 30\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "fig_size2 = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '../train/text/CSV'\n",
    "train_meta = pd.read_csv(os.path.join(train_csv_path, 'trainGrayClipped_meta.csv'))\n",
    "\n",
    "data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "dataset_frames_num = train_meta.shape[0]\n",
    "train_frames_num = int(.8*(dataset_frames_num-1))\n",
    "\n",
    "train_index = data_index[:train_frames_num]\n",
    "val_index = data_index[train_frames_num:]\n",
    "print(train_index, val_index)\n",
    "plt.plot(train_meta['speed'][train_index], 'ro')\n",
    "plt.plot(train_meta['speed'][val_index], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
