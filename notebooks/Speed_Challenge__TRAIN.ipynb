{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ELU\n",
    "from keras.layers import Lambda, Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../train/assets/model=keras_elu_C40_C20_De128_De64_De15_De1-batch_size=20-num_epoch=20-steps_per_epoch=400__2/history.p \n",
      " ../train/assets/model=keras_elu_C40_C20_De128_De64_De15_De1-batch_size=20-num_epoch=20-steps_per_epoch=400__2/weights.h5 \n",
      " ../train/assets/model=keras_elu_C40_C20_De128_De64_De15_De1-batch_size=20-num_epoch=20-steps_per_epoch=400__2/model=keras_elu_C40_C20_De128_De64_De15_De1-batch_size=20-num_epoch=20-steps_per_epoch=400__2\n"
     ]
    }
   ],
   "source": [
    "model_name = 'keras'\n",
    "batch_size = 20\n",
    "epoch_num = 20\n",
    "steps_per_epoch = 400\n",
    "\n",
    "asset_path = '../train/assets'\n",
    "#train_name = f'model={model_name}_C24_C36_C48_D50_C64_C64_De100_De50_De10_De1-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}'\n",
    "#train_name = f'model={model_name}2_elu_C40P_C20P_D25_De128_D30_De64_De15_De1-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}'\n",
    "#train_name = f'model={model_name}_elu_C40_C20_D25_De128_D30_De64_De15_De1-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}__3'\n",
    "#train_name = f'model={model_name}_elu_C40_C20_D35_De128_De64_De15_De1-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}__4'\n",
    "train_name = f'model={model_name}_elu_C40_C20_De128_De64_De15_De1-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}__2'\n",
    "train_path = os.path.join(asset_path, train_name)\n",
    "\n",
    "train_meta_loc = os.path.join(train_path, 'train_meta.csv')\n",
    "test_meta_loc = os.path.join(train_path, 'test_meta.csv')\n",
    "test_result_path = os.path.join(train_path, 'test.txt')\n",
    "history_loc = os.path.join(train_path, 'history.p')\n",
    "weights_loc = os.path.join(train_path, 'weights.h5')\n",
    "tensorboard_loc = os.path.join(train_path, train_name)\n",
    "print(history_loc, '\\n', weights_loc, '\\n', tensorboard_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 320, 3) 136 320 3\n"
     ]
    }
   ],
   "source": [
    "# Global Vars\n",
    "img = (cv.imread('../train/photos/images/gray_Clipped/0.jpg')).shape\n",
    "img_height = img[0]\n",
    "img_width = img[1]\n",
    "img_channels = img[2]\n",
    "print(img, img_height, img_width, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_Value(prvs_FRAME, curr_FRAME, HSV_value):\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME, cv.COLOR_BGR2HSV)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME, cv.COLOR_BGR2HSV)\n",
    "    prvs_FRAME[...,2] = prvs_FRAME[...,2]*HSV_value\n",
    "    curr_FRAME[...,2] = curr_FRAME[...,2]*HSV_value\n",
    "    return prvs_FRAME, curr_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlow_DENSE(prvs_FRAME, curr_FRAME, dynamic_sat):\n",
    "    # flow_mat = None\n",
    "    # image_scale = 0.5\n",
    "    # pyr_images = 1 # was 3\n",
    "    # win_size = 15\n",
    "    # pyr_iterations = 2 # was 3\n",
    "    # poly_expans = 5\n",
    "    # std = 1.3 # was 1.2\n",
    "    \n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    pyr_images = 1 # was 3\n",
    "    win_size = 10\n",
    "    pyr_iterations = 2 # was 3\n",
    "    poly_expans = 5\n",
    "    std = 1.3 # was 1.2\n",
    "\n",
    "    hsv = np.zeros_like(prvs_FRAME)\n",
    "    if dynamic_sat:\n",
    "        hsv[..., 1] = prvs_FRAME[..., 1]\n",
    "    else:\n",
    "        hsv[...,1] = 255\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME,cv.COLOR_BGR2GRAY)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME,cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs_FRAME,curr_FRAME,flow_mat,image_scale,pyr_images,win_size,pyr_iterations,poly_expans,std,0)\n",
    "    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "    print(hsv.dtype)\n",
    "    bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(train_meta, kLoopCount, train_index, getSpeed, for_training):\n",
    "    opt_flows = np.empty((0, img_height, img_width, img_channels), dtype='uint8')\n",
    "    speed = np.empty((0))\n",
    "    for k in range(kLoopCount):\n",
    "        HSV_value = np.random.uniform(low=.3, high=1.2)\n",
    "        #print(train_index)\n",
    "        curr_FRAME = cv.imread(train_meta['image_path'][train_index])\n",
    "        #curr_FRAME = curr_FRAME[100:440, :-90]\n",
    "        prvs_FRAME = cv.imread(train_meta['image_path'][train_index-1])\n",
    "        #prvs_FRAME = prvs_FRAME[100:440, :-90]\n",
    "        if getSpeed:\n",
    "            speed = np.append(speed, train_meta['speed'][train_index])\n",
    "        if for_training:\n",
    "            prvs_FRAME, curr_FRAME = adjust_Value(prvs_FRAME, curr_FRAME, HSV_value)\n",
    "        opt_flow = opticalFlow_DENSE(prvs_FRAME, curr_FRAME, False)\n",
    "        print(opt_flow.dtype)\n",
    "        opt_flow.dtype = 'uint8'\n",
    "        print(opt_flow.dtype)\n",
    "        opt_flows = np.append(opt_flows, [opt_flow], axis=0)\n",
    "        print(opt_flows.dtype)\n",
    "    if getSpeed:\n",
    "        return opt_flows, speed\n",
    "    else:\n",
    "        return opt_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData(train_meta, train_index, batchSize):\n",
    "    global img_height, img_width, img_channels\n",
    "    get_speed = True\n",
    "    for_training = True\n",
    "    while True:\n",
    "        opt_flow_arr = np.empty((0, img_height, img_width, img_channels))\n",
    "        speed_arr = np.empty((0))\n",
    "        index2 = 0\n",
    "        for i in range(batchSize):\n",
    "            #print(index2)\n",
    "            index = np.random.randint(0, train_index.shape[0])\n",
    "            opt_flow, speed = getData(train_meta, 1, train_index[index], get_speed, for_training)\n",
    "            opt_flow_arr = np.append(opt_flow_arr, opt_flow, axis=0)\n",
    "            speed_arr = np.append(speed_arr, speed)\n",
    "            index2 = index2 + 1\n",
    "        #print(opt_flow_arr.shape)\n",
    "        yield opt_flow_arr, speed_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValData(train_meta, val_index, batchSize, getSpeed):\n",
    "    for_training = False\n",
    "    while True:\n",
    "        index = 0\n",
    "        for i in range(len(val_index)):\n",
    "            if getSpeed:\n",
    "                opt_flow, speed = getData(train_meta, 1, val_index[index], getSpeed)\n",
    "            else:\n",
    "                opt_flow = getData(train_meta, 1, val_index[index], getSpeed, for_training)\n",
    "            #opt_flow_arr = np.append(opt_flow_arr, opt_flow)\n",
    "            index = index + 1\n",
    "            if getSpeed:\n",
    "                yield opt_flow, speed\n",
    "            else:\n",
    "                yield opt_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCNNModel():\n",
    "    global img_height, img_width, img_channels\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1, input_shape=(img_height, img_width, img_channels)))\n",
    "    model.add(Conv2D(filters=40, kernel_size=(5,5), strides=(3,3), activation='elu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=20, kernel_size=(5,5), strides=(2,2), activation='elu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(rate=0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='elu'))\n",
    "    #model.add(Dropout(rate=0.3))\n",
    "    model.add(Dense(units=64, activation='elu'))\n",
    "    model.add(Dense(units=15, activation='elu'))\n",
    "    model.add(Dense(units=1, activation='elu'))\n",
    "    opt = Adam(learning_rate=1e-4, epsilon=1e-08)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     # normalization    \n",
    "#     # perform custom normalization before lambda layer in network\n",
    "#     model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = (136,320,3)))\n",
    "\n",
    "#     model.add(Conv2D(24, (5, 5), \n",
    "#                      strides=(2,2), \n",
    "#                      padding = 'valid',\n",
    "#                      kernel_initializer = 'he_normal',\n",
    "#                      name = 'conv1'))\n",
    "    \n",
    "    \n",
    "#     model.add(ELU())    \n",
    "#     model.add(Conv2D(36, (5, 5), \n",
    "#                      strides=(2,2), \n",
    "#                      padding = 'valid',\n",
    "#                      kernel_initializer = 'he_normal',\n",
    "#                      name = 'conv2'))\n",
    "    \n",
    "#     model.add(ELU())    \n",
    "#     model.add(Conv2D(48, (5, 5), \n",
    "#                      strides=(2,2), \n",
    "#                      padding = 'valid',\n",
    "#                      kernel_initializer = 'he_normal',\n",
    "#                      name = 'conv3'))\n",
    "#     model.add(ELU())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Conv2D(64, (3, 3), \n",
    "#                      strides = (1,1), \n",
    "#                      padding = 'valid',\n",
    "#                      kernel_initializer = 'he_normal',\n",
    "#                      name = 'conv4'))\n",
    "    \n",
    "#     model.add(ELU())              \n",
    "#     model.add(Conv2D(64, (3, 3), \n",
    "#                      strides= (1,1), \n",
    "#                      padding = 'valid',\n",
    "#                      kernel_initializer = 'he_normal',\n",
    "#                      name = 'conv5'))\n",
    "              \n",
    "              \n",
    "#     model.add(Flatten(name = 'flatten'))\n",
    "#     model.add(ELU())\n",
    "#     model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "#     model.add(ELU())\n",
    "#     model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "#     model.add(ELU())\n",
    "#     model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "#     model.add(ELU())\n",
    "    \n",
    "#     # do not put activation at the end because we want to exact output, not a class identifier\n",
    "#     model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
    "    \n",
    "#     adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#     model.compile(optimizer = adam, loss = 'mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    global batch_size, epoch_num, steps_per_epoch, train_path\n",
    "    train_csv_path = '../train/text/CSV'\n",
    "    train_meta = pd.read_csv(os.path.join(train_csv_path, 'trainGrayClipped_meta.csv'))\n",
    "    \n",
    "    data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "    dataset_frames_num = train_meta.shape[0]\n",
    "    train_frames_num = int(.6*(dataset_frames_num-1))\n",
    "    val_frames_num = int(.5*(dataset_frames_num - train_frames_num))\n",
    "    \n",
    "    \n",
    "    train_index = data_index[:train_frames_num]\n",
    "    val_index = data_index[train_frames_num:(train_frames_num+val_frames_num)]\n",
    "    print(train_index.shape, val_index.shape)\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "    \n",
    "    valid_generator = getValData(train_meta, val_index, batch_size, True)\n",
    "    val_size = len(val_index)\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                                  patience=1, \n",
    "                                  verbose=1, \n",
    "                                  min_delta = 0.23,\n",
    "                                  mode='min',)\n",
    "    \n",
    "    modelCheckpoint = ModelCheckpoint(weights_loc, \n",
    "                                      monitor = 'val_loss', \n",
    "                                      save_best_only = True, \n",
    "                                      mode = 'min', \n",
    "                                      verbose = 1,\n",
    "                                     save_weights_only = True)\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0,\n",
    "                                write_graph=True, write_images=True)\n",
    "    callbacks_list = [modelCheckpoint, tensorboard, earlyStopping]\n",
    "    \n",
    "    model = createCNNModel()\n",
    "    print(model.summary())\n",
    "    \n",
    "    train_size = len(train_index)\n",
    "    train_generator = getTrainingData(train_meta, train_index, batch_size)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            steps_per_epoch = steps_per_epoch, \n",
    "            epochs = epoch_num,\n",
    "            callbacks = callbacks_list,\n",
    "            verbose = 1,\n",
    "            validation_data = valid_generator,\n",
    "            validation_steps = val_size)\n",
    "\n",
    "    print(history)\n",
    "    pickle.dump(history.history, open(history_loc, \"wb\"))\n",
    "    \n",
    "    return model, history.history, valid_generator, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12239,) (4080,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 136, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 44, 106, 40)       3040      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 51, 20)        20020     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20400)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               2611328   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                975       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,643,635\n",
      "Trainable params: 2,643,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d72e1d971014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-4ddd6305ded2>\u001b[0m in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     history = model.fit_generator(\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \"\"\"\n\u001b[0;32m-> 1718\u001b[0;31m         return training_generator.fit_generator(\n\u001b[0m\u001b[1;32m   1719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "uint8\n",
      "uint8"
     ]
    }
   ],
   "source": [
    "model, history, valid_generator, val_size = start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     \n",
      "====================================================================================================\n",
      "lambda_38 (Lambda)               (None, 136, 320, 3)   0           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 44, 106, 40)   3040        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 20, 51, 20)    20020       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)             (None, 20400)         0           \n",
      "____________________________________________________________________________________________________\n",
      "dense_149 (Dense)                (None, 128)           2611328     \n",
      "____________________________________________________________________________________________________\n",
      "dense_150 (Dense)                (None, 64)            8256        \n",
      "____________________________________________________________________________________________________\n",
      "dense_151 (Dense)                (None, 15)            975         \n",
      "____________________________________________________________________________________________________\n",
      "dense_152 (Dense)                (None, 1)             16          \n",
      "====================================================================================================\n",
      "Total params: 2,643,635\n",
      "Trainable params: 2,643,635\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#history = pickle.load(open(history_loc, \"rb\" ))\n",
    "model = createCNNModel()\n",
    "#model.load_weights(weights_loc)\n",
    "#adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#model.compile(optimizer = adam, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_print_fn(x):\n",
    "    dic = {'lambd':'L', 'conv2':'C', 'flatt':'F', 'dense':'De', 'dropo':'D'}\n",
    "    dic2 = ['C', 'D', 'De']\n",
    "    #if x[:5] in dic:\n",
    "        symbol = dic[x[:5]]\n",
    "        if symbol in dic2:\n",
    "            \n",
    "        #print(dic[x[:5]])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer Output Shape                                     Param #     \n",
      "====================================================================================================\n",
      "lambd (None, 136, 320, 3)                              0           \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (None, 44, 106, 40)                              3040        \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (None, 20, 51, 20)                               20020       \n",
      "____________________________________________________________________________________________________\n",
      "flatt (None, 20400)                                    0           \n",
      "____________________________________________________________________________________________________\n",
      "dense (None, 128)                                      2611328     \n",
      "____________________________________________________________________________________________________\n",
      "dense (None, 64)                                       8256        \n",
      "____________________________________________________________________________________________________\n",
      "dense (None, 15)                                       975         \n",
      "____________________________________________________________________________________________________\n",
      "dense (None, 1)                                        16          \n",
      "====================================================================================================\n",
      "Total params: 2,643,635\n",
      "Trainable params: 2,643,635\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=100, positions=[0.06,0.55,0.67,0.0], print_fn=a_print_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Provide either a layer name or layer index.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c5eef99ccb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provide either a layer name or layer index.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Provide either a layer name or layer index."
     ]
    }
   ],
   "source": [
    "model_info = model.get_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '../train/text/CSV'\n",
    "train_meta = pd.read_csv(os.path.join(train_csv_path, 'trainGrayClipped_meta.csv'))\n",
    "\n",
    "data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "dataset_frames_num = train_meta.shape[0]\n",
    "#train_frames_num = int(.8*(dataset_frames_num-1))\n",
    "train_frames_num = int(.6*(dataset_frames_num-1))\n",
    "val_frames_num = int(.5*((dataset_frames_num-1) - train_frames_num))\n",
    "test_frames_num = int(((dataset_frames_num-1) - (train_frames_num + val_frames_num)))\n",
    "print(train_frames_num, val_frames_num, test_frames_num)\n",
    "\n",
    "train_index = data_index[:train_frames_num]\n",
    "val_index = data_index[train_frames_num:(train_frames_num+val_frames_num)]\n",
    "test_index = data_index[(train_frames_num+val_frames_num):]\n",
    "train_generator = getValData(train_meta, train_index, batch_size, True)\n",
    "valid_generator = getValData(train_meta, val_index, batch_size, True)\n",
    "test_generator = getValData(train_meta, test_index, batch_size, True)\n",
    "val_size = len(val_index)\n",
    "test_size = len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(train_generator, steps=train_size)\n",
    "print('train score:', train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = model.evaluate(valid_generator, steps=val_size)\n",
    "print('val score:', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.evaluate(test_generator, steps=test_size)\n",
    "print('test score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], 'ro')\n",
    "plt.plot(history['val_loss'], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size)\n",
    "fig_size[0] = 30\n",
    "fig_size[1] = 30\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "fig_size2 = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '../train/text/CSV'\n",
    "train_meta = pd.read_csv(os.path.join(train_csv_path, 'trainGrayClipped_meta.csv'))\n",
    "\n",
    "data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "dataset_frames_num = train_meta.shape[0]\n",
    "train_frames_num = int(.70*(dataset_frames_num-1))\n",
    "\n",
    "train_index = data_index[:train_frames_num]\n",
    "val_index = data_index[train_frames_num:]\n",
    "print(train_index, val_index)\n",
    "plt.plot(train_meta['speed'][train_index], 'ro')\n",
    "plt.plot(train_meta['speed'][val_index], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSpeed(a_meta, a_meta_loc, getSpeed, setError):\n",
    "    global train_meta_loc, test_meta_loc, batch_size, weights_loc\n",
    "\n",
    "    dataset_frames_num = a_meta.shape[0]\n",
    "    print(dataset_frames_num)\n",
    "    \n",
    "    data_index = np.arange(1, (dataset_frames_num))\n",
    "    data_length = data_index.shape[0]\n",
    "    \n",
    "    data_gen = getValData(a_meta, data_index, batch_size, getSpeed)\n",
    "    \n",
    "    model = createCNNModel()\n",
    "    model.load_weights(weights_loc)\n",
    "    predicted_speed = model.predict(data_gen, steps=data_length, verbose=1)\n",
    "    predicted_speed.shape = dataset_frames_num-1\n",
    "    \n",
    "    a_meta = a_meta.assign(predicted_speed=pd.Series(np.empty((dataset_frames_num))).values)\n",
    "    a_meta.loc[:, 'predicted_speed'] = np.nan\n",
    "    a_meta.loc[1:,'predicted_speed'] = predicted_speed\n",
    "    \n",
    "    if setError:\n",
    "        a_meta = a_meta.assign(error=pd.Series(np.empty((dataset_frames_num))).values)\n",
    "        a_meta.loc[:]['error'] = np.nan\n",
    "        a_meta.loc[1:,'error'] = abs(a_meta.loc[1:, 'speed'] - predicted_speed)\n",
    "\n",
    "    a_meta.to_csv(a_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictSpeed(train_meta, train_meta_loc, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = pd.read_csv(train_meta_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(train_meta.loc[1:, 'speed'], train_meta.loc[1:, 'predicted_speed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(train_meta[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = train_meta.loc[:, :'error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta.to_csv(train_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_meta.loc[:,'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_meta.loc[:,'med_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_meta.loc[:,'mean_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_meta.loc[20376:, 'predicted_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_range = 50 # was 50\n",
    "#train_meta = train_meta.assign(med_prd_spd=pd.Series(np.empty((20400))).values)\n",
    "train_meta.loc[:, 'med_prd_spd'] = np.nan\n",
    "train_meta.loc[1:,'med_prd_spd'] = train_meta[1:]['predicted_speed'].rolling(weighted_range, center=True).median()\n",
    "train_meta.loc[1:25, 'med_prd_spd'] = train_meta.loc[1:25, 'predicted_speed']\n",
    "train_meta.loc[20376:, 'med_prd_spd'] = train_meta.loc[20376:, 'predicted_speed']\n",
    "#train_meta.to_csv(train_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_range = 50 # was 50\n",
    "#train_meta = train_meta.assign(mean_prd_spd=pd.Series(np.empty((20400))).values)\n",
    "train_meta.loc[:, 'mean_prd_spd'] = np.nan\n",
    "train_meta.loc[1:,'mean_prd_spd'] = train_meta[1:]['predicted_speed'].rolling(weighted_range, center=True).mean()\n",
    "train_meta.loc[1:25, 'mean_prd_spd'] = train_meta.loc[1:25, 'predicted_speed']\n",
    "train_meta.loc[20376:, 'mean_prd_spd'] = train_meta.loc[20376:, 'predicted_speed']\n",
    "#train_meta.to_csv(train_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_meta = train_meta.assign(med_error=pd.Series(np.empty((20400))).values)\n",
    "train_meta.loc[:]['med_error'] = np.nan\n",
    "train_meta.loc[1:,'med_error'] = abs(train_meta.loc[1:, 'speed'] - train_meta.loc[1:,'med_prd_spd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_meta = train_meta.assign(mean_error=pd.Series(np.empty((20400))).values)\n",
    "train_meta.loc[:]['mean_error'] = np.nan\n",
    "train_meta.loc[1:,'mean_error'] = abs(train_meta.loc[1:, 'speed'] - train_meta.loc[1:,'mean_prd_spd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta.to_csv(train_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(train_meta.loc[:,'error']))\n",
    "print(np.mean(train_meta.loc[:,'med_error']))\n",
    "print(np.mean(train_meta.loc[:,'mean_error']))\n",
    "print()\n",
    "print(mean_squared_error(train_meta.loc[1:, 'speed'], train_meta.loc[1:, 'predicted_speed']))\n",
    "print(mean_squared_error(train_meta.loc[1:, 'speed'], train_meta.loc[1:, 'med_prd_spd']))\n",
    "print(mean_squared_error(train_meta.loc[1:, 'speed'], train_meta.loc[1:, 'mean_prd_spd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "dataset_frames_num = train_meta.shape[0]\n",
    "#train_frames_num = int(.8*(dataset_frames_num-1))\n",
    "train_frames_num = int(.6*(dataset_frames_num-1))\n",
    "val_frames_num = int(.5*((dataset_frames_num-1) - train_frames_num))\n",
    "test_frames_num = int(((dataset_frames_num-1) - (train_frames_num + val_frames_num)))\n",
    "print(train_frames_num, val_frames_num, test_frames_num, train_frames_num+val_frames_num+test_frames_num)\n",
    "\n",
    "train_index = data_index[:train_frames_num]\n",
    "val_index = data_index[train_frames_num:(train_frames_num+val_frames_num)]\n",
    "test_index = data_index[(train_frames_num+val_frames_num):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 0\n",
    "test2 = 0\n",
    "test3 = 0\n",
    "for i in train_index:\n",
    "    test1 = test1 + train_meta.loc[i, 'error']\n",
    "test1_loss = test1/train_frames_num\n",
    "for i in val_index:\n",
    "    test2 = test2 + train_meta.loc[i, 'error']\n",
    "test2_loss = test2/val_frames_num\n",
    "for i in test_index:\n",
    "    test3 = test3 + train_meta.loc[i, 'error']\n",
    "test3_loss = test3/test_frames_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test1_loss, test2_loss, test3_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = '../test/text/CSV'\n",
    "test_meta = pd.read_csv(os.path.join(test_csv_path, 'testGrayClipped_meta.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictSpeed(test_meta, test_meta_loc, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta = pd.read_csv(test_meta_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(test_meta[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_range = 100 # was 50\n",
    "#test_meta = test_meta.assign(med_prd_spd=pd.Series(np.empty((20400))).values)\n",
    "test_meta.loc[:, 'med_prd_spd'] = np.nan\n",
    "test_meta.loc[1:,'med_prd_spd'] = test_meta[1:]['predicted_speed'].rolling(weighted_range, center=True).median()\n",
    "test_meta.loc[1:25, 'med_prd_spd'] = test_meta.loc[1:25, 'predicted_speed']\n",
    "test_meta.loc[10774:, 'med_prd_spd'] = test_meta.loc[10774:, 'predicted_speed']\n",
    "#test_meta.to_csv(test_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_range = 100 # was 50\n",
    "#test_meta = test_meta.assign(mean_prd_spd=pd.Series(np.empty((20400))).values)\n",
    "test_meta.loc[:, 'mean_prd_spd'] = np.nan\n",
    "test_meta.loc[1:,'mean_prd_spd'] = test_meta[1:]['predicted_speed'].rolling(weighted_range, center=True).mean()\n",
    "test_meta.loc[1:25, 'mean_prd_spd'] = test_meta.loc[1:25, 'predicted_speed']\n",
    "test_meta.loc[10774:, 'mean_prd_spd'] = test_meta.loc[10774:, 'predicted_speed']\n",
    "#test_meta.to_csv(test_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta.to_csv(test_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_length = test_meta.loc[1080:1640].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 0\n",
    "test2 = 0\n",
    "test3 = 0\n",
    "for i in test_meta.loc[1080:1640, 'predicted_speed']:\n",
    "    test1 = test1 + i\n",
    "test1_loss = test1/stop_length\n",
    "for i in test_meta.loc[1080:1640, 'med_prd_spd']:\n",
    "    test2 = test2 + i\n",
    "test2_loss = test2/stop_length\n",
    "for i in test_meta.loc[1080:1640, 'mean_prd_spd']:\n",
    "    test3 = test3 + i\n",
    "test3_loss = test3/stop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test1_loss, test2_loss, test3_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = test_meta.loc[:, 'med_prd_spd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv(test_result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size)\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "fig_size2 = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_meta.loc[1:, 'image_index'], train_meta.loc[1:, 'predicted_speed'], 'bx')\n",
    "plt.plot(train_meta.loc[1:, 'image_index'], train_meta.loc[1:, 'speed'], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_meta.loc[1:, 'image_index'], train_meta.loc[1:, 'med_prd_spd'], 'bx')\n",
    "plt.plot(train_meta.loc[1:, 'image_index'], train_meta.loc[1:, 'speed'], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_meta.loc[1:, 'image_index'], train_meta.loc[1:, 'mean_prd_spd'], 'bx')\n",
    "plt.plot(train_meta.loc[1:, 'image_index'], train_meta.loc[1:, 'speed'], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_meta.loc[1:, 'image_index'], test_meta.loc[1:, 'predicted_speed'], 'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_meta.loc[1:, 'image_index'], test_meta.loc[1:, 'med_prd_spd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_meta.loc[1:, 'image_index'], test_meta.loc[1:, 'mean_prd_spd'], 'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
