{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ELU\n",
    "from keras.layers import Lambda, Dense, Dropout, Flatten\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Vars\n",
    "img = (cv.imread('../train/photos/images/gray_Clipped/0.jpg')).shape\n",
    "img_height = img[0]\n",
    "img_width = img[1]\n",
    "# img_channels = img[2]\n",
    "img_channels = 2\n",
    "print(img, img_height, img_width, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_Value(prvs_FRAME, curr_FRAME, HSV_value):\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME, cv.COLOR_BGR2HSV)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME, cv.COLOR_BGR2HSV)\n",
    "    prvs_FRAME[...,2] = prvs_FRAME[...,2]*HSV_value\n",
    "    curr_FRAME[...,2] = curr_FRAME[...,2]*HSV_value\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME, cv.COLOR_HSV2BGR)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME, cv.COLOR_HSV2BGR)\n",
    "    return prvs_FRAME, curr_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlow_DENSE(prvs_FRAME, curr_FRAME, dynamic_sat):\n",
    "    global img_height, img_width, img_channels\n",
    "    \n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    pyr_images = 1 # was 3\n",
    "    win_size = 20\n",
    "    pyr_iterations = 10 # was 3, 2; 10 seems to be doing well clearing up the image; 20 is too much for little gain\n",
    "    poly_expans = 5 # was 5; 5 seems to be the best\n",
    "    std = 5 # was 1.2 was 2.3; higher seems to be better ex:5,10\n",
    "\n",
    "    #hsv = np.zeros_like(prvs_FRAME)\n",
    "    hsv = np.zeros((img_height, img_width, img_channels), dtype='float32')\n",
    "    #if dynamic_sat:\n",
    "        #hsv[..., 1] = cv.cvtColor(prvs_FRAME, cv.COLOR_BGR2HSV)[...,1]\n",
    "    #else:\n",
    "        #hsv[...,1] = 255\n",
    "    prvs_FRAME = cv.cvtColor(prvs_FRAME,cv.COLOR_BGR2GRAY)\n",
    "    curr_FRAME = cv.cvtColor(curr_FRAME,cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs_FRAME,curr_FRAME,flow_mat,image_scale,pyr_images,win_size,pyr_iterations,poly_expans,std,0)\n",
    "    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*(180/np.pi/2)\n",
    "    mag[mag>100]= 100\n",
    "    hsv[...,1] = mag/100\n",
    "    #hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "    #hsv = np.asarray(hsv, dtype=np.float32)\n",
    "    #bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "    #return bgr\n",
    "    return hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(train_meta, kLoopCount, train_index, doubleSpeed, getSpeed, for_training):\n",
    "    global img_height, img_width, img_channels\n",
    "    opt_flows = np.empty((0, img_height, img_width, img_channels), dtype='float32')\n",
    "    speed = np.empty((0))\n",
    "    for k in range(kLoopCount):\n",
    "        HSV_value = np.random.uniform(low=.5, high=1.2)\n",
    "        #print(train_index)\n",
    "        curr_FRAME = cv.imread(train_meta['image_path'][train_index])\n",
    "        if doubleSpeed:\n",
    "            prvs_FRAME = cv.imread(train_meta['image_path'][train_index-2])\n",
    "        else:\n",
    "            prvs_FRAME = cv.imread(train_meta['image_path'][train_index-1])\n",
    "        if getSpeed:\n",
    "            speed1 = train_meta['speed'][train_index]\n",
    "            speed2 = train_meta['speed'][train_index-1]\n",
    "            speed3 = np.mean((speed1, speed2))\n",
    "            speed4 = speed1+speed2\n",
    "            if doubleSpeed:\n",
    "                speed = np.append(speed, speed4)\n",
    "            else:\n",
    "                speed = np.append(speed, speed1)\n",
    "            #speed = np.append(speed, speed1)\n",
    "        if for_training:\n",
    "            prvs_FRAME, curr_FRAME = adjust_Value(prvs_FRAME, curr_FRAME, HSV_value)\n",
    "        opt_flow = opticalFlow_DENSE(prvs_FRAME, curr_FRAME, False)\n",
    "#         opt_flows = np.append(opt_flows, [opt_flow], axis=0)\n",
    "        opt_flows = np.append(opt_flows, [np.asarray(opt_flow, dtype=np.float32)], axis=0)\n",
    "    if getSpeed:\n",
    "        return opt_flows, speed\n",
    "    else:\n",
    "        return opt_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData(train_meta, train_index, batchSize):\n",
    "    global img_height, img_width, img_channels#, index_count\n",
    "    get_speed = True\n",
    "    for_training = True\n",
    "    while True:\n",
    "        opt_flow_arr = np.empty((0, img_height, img_width, img_channels))\n",
    "        speed_arr = np.empty((0))\n",
    "        for i in range(batchSize):\n",
    "            index = np.random.randint(0, train_index.shape[0], dtype='int16')\n",
    "            doubleSpeed = np.random.randint(0, 10)\n",
    "            if doubleSpeed < 2:\n",
    "                doubleSpeed = True\n",
    "            else:\n",
    "                doubleSpeed = False\n",
    "            opt_flow, speed = getData(train_meta, 1, train_index[index], doubleSpeed, get_speed, for_training)\n",
    "            opt_flow_arr = np.append(opt_flow_arr, opt_flow, axis=0)\n",
    "            speed_arr = np.append(speed_arr, speed)\n",
    "        yield opt_flow_arr, speed_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValData(train_meta, val_index, getSpeed):\n",
    "    doubleSpeed = False\n",
    "    for_training = False\n",
    "    while True:\n",
    "        index = 0\n",
    "        for i in range(len(val_index)):\n",
    "            if getSpeed:\n",
    "                opt_flow, speed = getData(train_meta, 1, val_index[index], doubleSpeed, getSpeed, for_training)\n",
    "            else:\n",
    "                opt_flow = getData(train_meta, 1, val_index[index], doubleSpeed, getSpeed, for_training)\n",
    "            #opt_flow_arr = np.append(opt_flow_arr, opt_flow)\n",
    "            index = index + 1\n",
    "            if getSpeed:\n",
    "                yield opt_flow, speed\n",
    "            else:\n",
    "                yield opt_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCNNModel():\n",
    "    global img_height, img_width, img_channels, num_layers, activ, reg, learning_rate, epsilon, loss\n",
    "    global kern_init, reg2, pad, custom_opt\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x, input_shape=(img_height, img_width, img_channels)))\n",
    "    #model.add(Lambda(lambda x: x / 127.5 - 1, input_shape=(img_height, img_width, img_channels)))\n",
    "    #uniform_initializer = RandomUniform(minval=1e-10, maxval=1e-9, seed=1)\n",
    "    \n",
    "    model.add(Conv2D(filters=160, \n",
    "                     kernel_size=(5,5), \n",
    "                     strides=(3,3), \n",
    "                     activation=activ))#, padding=pad, kernel_initializer = kern_init, kernel_regularizer=l2(reg2)))\n",
    "    model.add(MaxPooling2D((10, 10)))\n",
    "    if num_layers > 1:\n",
    "        model.add(Conv2D(filters=320, \n",
    "                     kernel_size=(5,5), \n",
    "                     strides=(3,3), \n",
    "                     activation=activ))#, padding=pad, kernel_initializer = kern_init, kernel_regularizer=l2(reg2)))\n",
    "        model.add(MaxPooling2D((3, 3)))\n",
    "    if num_layers > 2:\n",
    "        model.add(Conv2D(filters=640, \n",
    "                     kernel_size=(5,5), \n",
    "                     strides=(3,3), \n",
    "                     activation=activ))#, padding=pad, kernel_initializer = kern_init, kernel_regularizer=l2(reg2)))\n",
    "        model.add(MaxPooling2D((3, 3)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=128, activation=activ))#, kernel_initializer=kern_init, kernel_regularizer=l2(reg)))\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "\n",
    "    model.add(Dense(units=64, activation=activ))#, kernel_initializer=kern_init, kernel_regularizer=l2(reg)))\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    #model.add(Dense(units=32, activation='elu'))#, kernel_initializer=kern_init, kernel_regularizer=l2(reg)))\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(units=16, activation=activ))#, kernel_initializer=kern_init, kernel_regularizer=l2(reg)))\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(units=1, activation=activ))#, kernel_initializer=kern_init, kernel_regularizer=l2(reg)))\n",
    "    \n",
    "    if custom_opt:\n",
    "        opt = Adam(learning_rate=learning_rate, epsilon=epsilon) # was 1e-3    was 3e-5\n",
    "    else:\n",
    "        opt = 'adam'\n",
    "    print(opt)\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_print_fn(x):\n",
    "    global train_name, model_structure\n",
    "    dic = {'lambd':'L', 'conv2':'C', 'max_p':'P', 'flatt':'F', 'dense':'De', 'dropo':'D'}\n",
    "    dic2 = {'C':4, 'De':0}\n",
    "    dic3 = {',':0, ')':1, ' ':0}\n",
    "    if x[:5] in dic:\n",
    "        symbol = dic[x[:5]]\n",
    "        symbol_unit = ''\n",
    "        index = 13\n",
    "        commaSpace_count = 0\n",
    "        if symbol in dic2:\n",
    "            while True:\n",
    "                symbol_num = x[index]\n",
    "                if symbol_num not in dic3:\n",
    "                    if commaSpace_count == dic2[symbol]:\n",
    "                        symbol_unit = symbol_unit + symbol_num\n",
    "                    index = index + 1\n",
    "                else:\n",
    "                    if commaSpace_count == dic2[symbol]:\n",
    "                        break\n",
    "                    commaSpace_count = commaSpace_count+1\n",
    "                    index = index + 1\n",
    "        train_name = train_name + '-' + symbol + symbol_unit\n",
    "#         print(train_name)\n",
    "#     print(x)\n",
    "    model_structure = np.append(model_structure, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def setGlobal(model_name, batch_size, epoch_num, steps_per_epoch, model):\n",
    "    global train_path, model_train_meta_loc, model_train_meta_loc2, model_structure, train_name\n",
    "    global model_test_meta_loc, model_test_meta_loc2, test_result_path, test_result_path2\n",
    "    global history_loc, weights_loc, weights_loc2, weights_loc3, activ\n",
    "    # model_name = 'keras'\n",
    "    #model_name = 'grayClipped'\n",
    "    #batch_size = 40\n",
    "    #epoch_num = 40\n",
    "    #steps_per_epoch = 400\n",
    "\n",
    "    # asset_path = '../train/assets'\n",
    "    # train_name = f'model={model_name}_elu_C40_C20_De128_De64_De15_De1-batch_size={batch_size}-num_epoch={epoch_num}-steps_per_epoch={steps_per_epoch}'\n",
    "\n",
    "    model_structure = np.empty((0))\n",
    "    asset_path = '../train/assets/models2'\n",
    "    train_name = f'model={model_name}-{activ}'\n",
    "    model.summary(line_length=100, positions=[0.06,0.55,0.67,0.0], print_fn=a_print_fn)\n",
    "\n",
    "    train_name_end = f'-B={batch_size}-E={epoch_num}-SP={steps_per_epoch}-R='\n",
    "    # Need to manually change the ending.\n",
    "    #train_name2 = train_name + train_name_end2 + '-5'\n",
    "    train_name = train_name + train_name_end + 'NA'\n",
    "\n",
    "    train_path = os.path.join(asset_path, train_name)\n",
    "    #train_path2 = os.path.join(asset_path, train_name2)\n",
    "\n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "        model_structure_loc = os.path.join(train_path, 'model_structure.txt')\n",
    "        model_structure.tofile(model_structure_loc,sep=\"\\n\",format=\"%s\")\n",
    "\n",
    "    model_train_meta_loc = os.path.join(train_path, 'train_meta.csv')\n",
    "    model_test_meta_loc = os.path.join(train_path, 'test_meta.csv')\n",
    "    test_result_path = os.path.join(train_path, 'test.txt')\n",
    "    model_train_meta_loc2 = os.path.join(train_path, 'train_meta2.csv')\n",
    "    model_test_meta_loc2 = os.path.join(train_path, 'test_meta2.csv')\n",
    "    test_result_path2 = os.path.join(train_path, 'test2.txt')\n",
    "\n",
    "    history_loc = os.path.join(train_path, 'history.p')\n",
    "    weights_loc = os.path.join(train_path, 'weights.h5')\n",
    "    weights_loc2 = os.path.join(train_path, 'weights2.h5')\n",
    "    \n",
    "    #weights_loc3 = os.path.join(train_path2, 'weights2.h5')\n",
    "\n",
    "    # index_count = np.zeros((20399), dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(model_name, batch_size, epoch_num, steps_per_epoch, initial_epoch, load_weights, onlySet_global):\n",
    "    global train_meta_loc, test_meta_loc, train_path\n",
    "    \n",
    "    model = createCNNModel()\n",
    "    setGlobal(model_name, batch_size, epoch_num, steps_per_epoch, model)\n",
    "    if load_weights:\n",
    "        model.load_weights(weights_loc3)\n",
    "    \n",
    "    train_meta_loc = '../train/text/CSV'\n",
    "    train_meta_loc = os.path.join(train_meta_loc, 'trainGrayClipped_meta.csv')\n",
    "    test_meta_loc = '../test/text/CSV'\n",
    "    test_meta_loc = os.path.join(test_meta_loc, 'testGrayClipped_meta.csv')\n",
    "    \n",
    "    if onlySet_global:\n",
    "        return 0\n",
    "    \n",
    "    train_meta = pd.read_csv(train_meta_loc)\n",
    "    train_meta_length = train_meta.shape[0]\n",
    "    test_meta = pd.read_csv(test_meta_loc)\n",
    "    test_meta_length = test_meta.shape[0]\n",
    "    \n",
    "    # Adding instances of zero speed from test.mp4\n",
    "    stop_index_array = np.empty((0), dtype='int16')\n",
    "    stop_index_array = np.append(stop_index_array, np.arange(1080,1640), axis=0)\n",
    "    stop_index_array = np.append(stop_index_array, np.arange(6150,6200), axis=0)\n",
    "    stop_index_array = np.append(stop_index_array, np.arange(6650,6700), axis=0)\n",
    "    stop_index_array = np.append(stop_index_array, np.arange(7400,7430), axis=0)\n",
    "    stop_index_array = np.append(stop_index_array, np.arange(8230,8330), axis=0)\n",
    "    stop_index_array = np.append(stop_index_array, np.arange(8920,8945), axis=0)\n",
    "    \n",
    "    for idx, i in enumerate(stop_index_array):\n",
    "        train_meta.loc[train_meta_length+idx] = test_meta.loc[i]\n",
    "    #print('CSV len with stop:', train_meta.shape[0])\n",
    "    train_meta.loc[train_meta_length:, 'speed'] = 0\n",
    "    \n",
    "    #data_index = np.loadtxt('../train/text/train_val_index.txt', np.dtype('int16'), delimiter='\\n')\n",
    "    data_index = np.arange(1, train_meta.shape[0])\n",
    "    data_index[0] = (data_index[0] + 1)\n",
    "    data_index[20399] = (data_index[20399] + 2)\n",
    "    data_index[20400] = (data_index[20400] + 2)\n",
    "    rng_state = np.random.get_state(1)\n",
    "    np.random.shuffle(data_index)\n",
    "    dataset_frames_num = data_index.shape[0]\n",
    "    train_frames_num = int(.8*(dataset_frames_num))\n",
    "    val_frames_num = int(.5*(dataset_frames_num - train_frames_num))\n",
    "    #print('Train len:', train_frames_num, 'Val len:', val_frames_num)\n",
    "    \n",
    "    \n",
    "    train_index = data_index[:train_frames_num]\n",
    "    val_index = data_index[train_frames_num:(train_frames_num+val_frames_num)]\n",
    "    #print('Train Index len:', train_index.shape, 'Val Index len:', val_index.shape)\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "    \n",
    "    valid_generator = getValData(train_meta, val_index, True)\n",
    "    val_size = len(val_index)\n",
    "    train_size = len(train_index)\n",
    "    train_generator = getTrainingData(train_meta, train_index, batch_size)\n",
    "    \n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                                  patience=1, \n",
    "                                  verbose=1, \n",
    "                                  min_delta = 0.23,\n",
    "                                  mode='min',)\n",
    "    modelCheckpoint = ModelCheckpoint(weights_loc, \n",
    "                                      monitor = 'val_loss', \n",
    "                                      save_best_only = True, \n",
    "                                      mode = 'min', \n",
    "                                      verbose = 1,\n",
    "                                     save_weights_only = True)\n",
    "    modelCheckpoint2 = ModelCheckpoint(weights_loc2, \n",
    "                                      monitor = 'loss', \n",
    "                                      save_best_only = True, \n",
    "                                      mode = 'min', \n",
    "                                      verbose = 1,\n",
    "                                     save_weights_only = True)\n",
    "    \n",
    "    callbacks_list = [modelCheckpoint, modelCheckpoint2]\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            steps_per_epoch = steps_per_epoch, \n",
    "            epochs = epoch_num,\n",
    "            #initial_epoch = initial_epoch,\n",
    "            callbacks = callbacks_list,\n",
    "            verbose = 1,\n",
    "            validation_data = valid_generator,\n",
    "            validation_steps = val_size)\n",
    "\n",
    "    pickle.dump(history.history, open(history_loc, \"wb\"))\n",
    "    \n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "activ = 'elu'\n",
    "reg = 0\n",
    "learning_rate = 1e-3\n",
    "epsilon = 1e-7\n",
    "loss = 'mse'\n",
    "\n",
    "kern_init = 'zeros'\n",
    "reg2 = 0\n",
    "pad = 'valid'\n",
    "custom_opt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "activ = 'elu'\n",
    "reg = 0\n",
    "learning_rate = 1e-3\n",
    "epsilon = 1e-8\n",
    "loss = 'mse'\n",
    "\n",
    "kern_init = 'zeros'\n",
    "reg2 = 0\n",
    "pad = 'valid'\n",
    "custom_opt = 1\n",
    "\n",
    "            #     model_name    B   E  SP  IE   LW     GO\n",
    "history = start('grayClipped', 40, 10, 400, 0, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "activ = 'elu'\n",
    "reg = 0\n",
    "learning_rate = 1e-4\n",
    "epsilon = 1e-8\n",
    "loss = 'mse'\n",
    "\n",
    "kern_init = 'zeros'\n",
    "reg2 = 0\n",
    "pad = 'valid'\n",
    "custom_opt = 1\n",
    "\n",
    "            #     model_name    B   E  SP  IE   LW     GO\n",
    "history = start('grayClipped', 40, 10, 400, 0, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "activ = 'elu'\n",
    "reg = 0\n",
    "learning_rate = 1e-5\n",
    "epsilon = 1e-8\n",
    "loss = 'mse'\n",
    "\n",
    "kern_init = 'zeros'\n",
    "reg2 = 0\n",
    "pad = 'valid'\n",
    "custom_opt = 1\n",
    "\n",
    "            #     model_name    B   E  SP  IE   LW     GO\n",
    "history = start('grayClipped', 40, 10, 400, 0, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "            #     model_name    B   E  SP  IE   LW     GO\n",
    "history = start('grayClipped', 40, 10, 100, 0, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #     model_name    B   E  SP  IE   LW     GO\n",
    "history = start('grayClipped', 40, 10, 400, 0, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "            #     model_name    B   E  SP  IE   LW     GO\n",
    "history = start('grayClipped', 40, 10, 400, 0, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle.load(open(history_loc, \"rb\" ))\n",
    "print(history['loss'])\n",
    "plt.plot(history['loss'], 'ro')\n",
    "plt.plot(history['val_loss'], 'go')\n",
    "plt.grid(which='both', axis='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSpeed(a_meta, a_meta_loc, a_weights_loc, getSpeed, setError):\n",
    "    global model_train_meta_loc, model_test_meta_loc, batch_size\n",
    "\n",
    "    dataset_frames_num = a_meta.shape[0]\n",
    "    print(dataset_frames_num)\n",
    "    \n",
    "    data_index = np.arange(1, (dataset_frames_num))\n",
    "    data_length = data_index.shape[0]\n",
    "    print(data_length)\n",
    "    \n",
    "    data_gen = getValData(a_meta, data_index, getSpeed)\n",
    "    \n",
    "    model = createCNNModel()\n",
    "    model.load_weights(a_weights_loc)\n",
    "    \n",
    "    predicted_speed = model.predict(data_gen, steps=data_length, verbose=1)\n",
    "    predicted_speed.shape = dataset_frames_num-1\n",
    "    \n",
    "    a_meta = a_meta.assign(predicted_speed=pd.Series(np.empty((dataset_frames_num))).values)\n",
    "    a_meta.loc[:, 'predicted_speed'] = np.nan\n",
    "    a_meta.loc[1:,'predicted_speed'] = predicted_speed\n",
    "    \n",
    "    if setError:\n",
    "        a_meta = a_meta.assign(error=pd.Series(np.empty((dataset_frames_num))).values)\n",
    "        a_meta.loc[:, 'error'] = np.nan\n",
    "        a_meta.loc[1:,'error'] = abs(a_meta.loc[1:, 'speed'] - predicted_speed)\n",
    "\n",
    "    a_meta.to_csv(a_meta_loc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_median(a_meta, a_meta_loc, window_size, is_train):\n",
    "    a_meta_length = a_meta.shape[0]\n",
    "    is_odd = window_size%2\n",
    "    beg_missing_range = int(window_size/2) if is_odd else int(window_size/2)\n",
    "    end_missing_range = a_meta_length-beg_missing_range if is_odd else a_meta_length-(beg_missing_range-1)\n",
    "    a_meta.loc[:, f'{window_size}med_prd_spd'] = np.nan\n",
    "    a_meta.loc[1:,f'{window_size}med_prd_spd'] = a_meta[1:]['predicted_speed'].rolling(window_size, center=True).median()\n",
    "    a_meta.loc[1:beg_missing_range,f'{window_size}med_prd_spd']=a_meta.loc[beg_missing_range+1, f'{window_size}med_prd_spd'] # was 25 50\n",
    "    a_meta.loc[end_missing_range:,f'{window_size}med_prd_spd']=a_meta.loc[end_missing_range-1, f'{window_size}med_prd_spd'] # was 20376 20351\n",
    "\n",
    "    if is_train:\n",
    "        a_meta.loc[:][f'{window_size}med_error'] = np.nan\n",
    "        a_meta.loc[1:,f'{window_size}med_error'] = abs(a_meta.loc[1:, 'speed'] - a_meta.loc[1:,f'{window_size}med_prd_spd'])\n",
    "    a_meta.to_csv(a_meta_loc, index=False)\n",
    "    print(is_odd, beg_missing_range, end_missing_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopSignSpeed(a_meta):\n",
    "    stop_length = a_meta.loc[1080:1640].shape[0]\n",
    "    test1 = 0\n",
    "    test2 = 0\n",
    "    test3 = 0\n",
    "    for i in a_meta.loc[1080:1640, 'predicted_speed']:\n",
    "        test1 = test1 + i\n",
    "    test1_loss = test1/stop_length\n",
    "    for i in a_meta.loc[1080:1640, '50med_prd_spd']:\n",
    "        test2 = test2 + i\n",
    "    test2_loss = test2/stop_length\n",
    "    for i in a_meta.loc[1080:1640, '100med_prd_spd']:\n",
    "        test3 = test3 + i\n",
    "    test3_loss = test3/stop_length\n",
    "    \n",
    "    print(test1_loss, test2_loss, test3_loss)\n",
    "def printMSE(a_meta, is_train, start=1, stop=None):\n",
    "    if is_train:\n",
    "        data_index = np.arange(1, a_meta.shape[0])\n",
    "        rng_state = np.random.get_state(1)\n",
    "        np.random.shuffle(data_index)\n",
    "        dataset_frames_num = data_index.shape[0]\n",
    "        train_frames_num = int(.8*(dataset_frames_num))\n",
    "        val_frames_num = int(.5*(dataset_frames_num - train_frames_num))\n",
    "        test_frames_num = int((dataset_frames_num - (train_frames_num+val_frames_num)))\n",
    "        print('Train len:', train_frames_num, 'Val len:', val_frames_num, 'Test len:', test_frames_num)\n",
    "\n",
    "\n",
    "        train_index = data_index[:train_frames_num]\n",
    "        val_index = data_index[train_frames_num:(train_frames_num+val_frames_num)]\n",
    "        test_index = data_index[(train_frames_num+val_frames_num):]\n",
    "        \n",
    "#         start = 1 if start is None else start\n",
    "        stop = a_meta.shape[0]-1 if stop is None else stop\n",
    "        print(mean_squared_error(a_meta.loc[train_index, 'speed'], a_meta.loc[train_index, 'predicted_speed']),\n",
    "             mean_squared_error(a_meta.loc[val_index, 'speed'], a_meta.loc[val_index, 'predicted_speed']),\n",
    "             mean_squared_error(a_meta.loc[test_index, 'speed'], a_meta.loc[test_index, 'predicted_speed']))\n",
    "        \n",
    "        print(mean_squared_error(a_meta.loc[start:stop, 'speed'], a_meta.loc[start:stop, '50med_prd_spd']))\n",
    "        print(mean_squared_error(a_meta.loc[start:stop, 'speed'], a_meta.loc[start:stop, '100med_prd_spd']))\n",
    "    else:\n",
    "        print(mean_squared_error(np.zeros((1641-1080)), a_meta.loc[1080:1640, 'predicted_speed']))\n",
    "        print(mean_squared_error(np.zeros((1641-1080)), a_meta.loc[1080:1640, '50med_prd_spd']))\n",
    "        print(mean_squared_error(np.zeros((1641-1080)), a_meta.loc[1080:1640, '100med_prd_spd']))\n",
    "def printMeta(a_meta, start=0, stop=None):\n",
    "#     start = 0 if start is None else start\n",
    "    stop = a_meta.shape[0] if stop is None else stop\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        display(a_meta[start:stop])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta1 = pd.read_csv(train_meta_loc)\n",
    "predictSpeed(train_meta1, model_train_meta_loc, weights_loc, False, True)\n",
    "\n",
    "train_meta2 = pd.read_csv(train_meta_loc)\n",
    "predictSpeed(train_meta2, model_train_meta_loc2, weights_loc2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta1 = pd.read_csv(model_train_meta_loc)\n",
    "rolling_median(train_meta1, model_train_meta_loc, 50, True)\n",
    "rolling_median(train_meta1, model_train_meta_loc, 100, True)\n",
    "\n",
    "train_meta2 = pd.read_csv(model_train_meta_loc2)\n",
    "rolling_median(train_meta2, model_train_meta_loc2, 50, True)\n",
    "rolling_median(train_meta2, model_train_meta_loc2, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta1 = pd.read_csv(model_train_meta_loc)\n",
    "printMSE(train_meta1, True)\n",
    "print()\n",
    "train_meta2 = pd.read_csv(model_train_meta_loc2)\n",
    "printMSE(train_meta2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta1 = pd.read_csv(test_meta_loc)\n",
    "predictSpeed(test_meta1, model_test_meta_loc, weights_loc, False, False)\n",
    "\n",
    "test_meta2 = pd.read_csv(test_meta_loc)\n",
    "predictSpeed(test_meta2, model_test_meta_loc2, weights_loc2, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta1 = pd.read_csv(model_test_meta_loc)\n",
    "rolling_median(test_meta1, model_test_meta_loc, 50, False)\n",
    "rolling_median(test_meta1, model_test_meta_loc, 100, False)\n",
    "\n",
    "test_meta2 = pd.read_csv(model_test_meta_loc2)\n",
    "rolling_median(test_meta2, model_test_meta_loc2, 50, False)\n",
    "rolling_median(test_meta2, model_test_meta_loc2, 100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta1 = pd.read_csv(model_test_meta_loc)\n",
    "stopSignSpeed(test_meta1)\n",
    "print()\n",
    "test_meta2 = pd.read_csv(model_test_meta_loc2)\n",
    "stopSignSpeed(test_meta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMSE(test_meta1, False)\n",
    "print()\n",
    "printMSE(test_meta2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = test_meta1.loc[:, '100med_prd_spd']\n",
    "test_result.to_csv(test_result_path, index=False)\n",
    "\n",
    "test_result = test_meta2.loc[:, '100med_prd_spd']\n",
    "test_result.to_csv(test_result_path2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta1 = pd.read_csv(model_train_meta_loc)\n",
    "train_meta2 = pd.read_csv(model_train_meta_loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta1 = pd.read_csv(model_test_meta_loc)\n",
    "test_meta2 = pd.read_csv(model_test_meta_loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size)\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "fig_size2 = plt.rcParams[\"figure.figsize\"]\n",
    "print(fig_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpeed(a_meta, is_train, saveFile, speed_type1, speed_type2=None):\n",
    "    global train_path\n",
    "    fig, ax = plt.subplots()\n",
    "    if speed_type2 is not None:\n",
    "        ax.plot(a_meta.loc[1:, 'image_index'], a_meta.loc[1:, speed_type2], 'r', linewidth=2)\n",
    "    if speed_type1 is not None:\n",
    "        ax.plot(a_meta.loc[1:, 'image_index'], a_meta.loc[1:, speed_type1], 'bo', markersize=2)\n",
    "    ax.grid(which='both', axis='both')\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(500))\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "    if is_train:\n",
    "        randomNumber = plt.xticks(np.arange(0, 20400, 2000))\n",
    "        randomNumber = plt.yticks(np.arange(0, 32, 2))\n",
    "    else:\n",
    "        randomNumber = plt.yticks(np.arange(0, 38, 2))\n",
    "        randomNumber = plt.xticks(np.arange(0, 10798, 1000))\n",
    "    if saveFile:\n",
    "        plotPath = os.path.join(train_path, speed_type1+'.png')\n",
    "        fig.savefig(plotPath, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta1, True, False, None, 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta2, True, False, None, 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta1, True, False, 'predicted_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta2, True, False, 'predicted_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta1, True, False, 'predicted_speed', 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta2, True, False, 'predicted_speed', 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta1, True, False, '50med_prd_spd', 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta2, True, False, '50med_prd_spd', 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta1, True, False, '100med_prd_spd', 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(train_meta2, True, False, '100med_prd_spd', 'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(test_meta1, False, False, '50med_prd_spd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(test_meta2, False, False, '50med_prd_spd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(test_meta1, False, False, '100med_prd_spd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(test_meta2, False, True, '100med_prd_spd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(test_meta1, False, False, 'predicted_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSpeed(test_meta2, False, False, 'predicted_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyOldPath = '../train/assets/model=keras_elu_C40_C20_De128_De64_De15_De1-batch_size=40-num_epoch=20-steps_per_epoch=400'\n",
    "a_meta_loc = os.path.join(reallyOldPath, 'test_meta.csv')\n",
    "a_meta=pd.read_csv(a_meta_loc)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(a_meta.loc[1:, 'image_index'], a_meta.loc[1:, 'med_prd_spd'], 'bo', markersize=2)\n",
    "ax.grid(which='both', axis='both')\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(500))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "randomNumber = plt.yticks(np.arange(0, 38, 2))\n",
    "randomNumber = plt.xticks(np.arange(0, 10798, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "randomArray = np.loadtxt('../adeebsTest.txt', np.dtype('float32'), delimiter='\\n')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(randomArray[:], 'b', linewidth=2)\n",
    "ax.plot(test_meta2.loc[1:, 'image_index'], test_meta2.loc[1:, '100med_prd_spd'], 'r', linewidth=2)#, markersize=2)\n",
    "ax.grid(which='both', axis='both')\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(500))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "randomNumber = plt.yticks(np.arange(0, 38, 2))\n",
    "randomNumber = plt.xticks(np.arange(0, 10798, 1000))\n",
    "plot_path = os.path.join(train_path, '100med_prd_spd-adeeb'+'.png')\n",
    "fig.savefig(plot_path, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomArray = np.loadtxt('../jovsaTest.txt', np.dtype('float32'), delimiter='\\n')\n",
    "print(randomArray.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(randomArray[:], 'bo', markersize=2)\n",
    "ax.grid(which='both', axis='both')\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(500))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "randomNumber = plt.yticks(np.arange(0, 25, 2))\n",
    "randomNumber = plt.xticks(np.arange(0, 10798, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomArray = np.loadtxt('../experienTest1.txt', np.dtype('float32'), delimiter='\\n')\n",
    "print(randomArray.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(randomArray[:], 'b')#, markersize=5)\n",
    "ax.grid(which='both', axis='both')\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(500))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "randomNumber = plt.yticks(np.arange(0, 26, 2))\n",
    "randomNumber = plt.xticks(np.arange(0, 10798, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
